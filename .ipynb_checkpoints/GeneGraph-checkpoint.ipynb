{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c389cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, metrics\n",
    "from keras.layers import Input, Dense, BatchNormalization, LSTM, Embedding, Bidirectional, Normalization, Conv1D, Dropout, MaxPool2D,MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61c5dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 13:41:02.658375: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "VERBOSE=False\n",
    "EPOCHS=25\n",
    "TRAIN_SIZE=.75\n",
    "\n",
    "METRICS = [\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'), \n",
    "      metrics.BinaryAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc'),\n",
    "      metrics.AUC(name='prc', curve='PR') # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7ff73",
   "metadata": {},
   "source": [
    "## get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2569f634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: CTD_chem_gene_ixns\n",
      "data already exists\n",
      "downloading: CTD_chemicals_diseases\n",
      "data already exists\n",
      "downloading: CTD_diseases\n",
      "data already exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def download_resource(resource):\n",
    "    url_dl_pattern = 'http://ctdbase.org/reports/{resource}.csv.gz'\n",
    "    url = url_dl_pattern.format(resource=resource)\n",
    "    \n",
    "    print('downloading: {0}'.format(resource))\n",
    "    local_filename = 'zipped_data/' + url.split('/')[-1]\n",
    "    unzipped_filename = 'unzipped_data/' + url.split('/')[-1].replace('.gz', '')\n",
    "    \n",
    "    if os.path.isfile(unzipped_filename):\n",
    "        print('data already exists')\n",
    "        return \n",
    "\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)\n",
    "\n",
    "    with gzip.open(local_filename, 'rb') as f_in:\n",
    "        with open(unzipped_filename, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "    return local_filename\n",
    "\n",
    "\n",
    "resources = [\n",
    "#     'CTD_chem_gene_ixn_types',\n",
    "#     'CTD_chem_pathways_enriched',\n",
    "#     'CTD_genes_diseases',\n",
    "#     'CTD_genes_pathways',\n",
    "#     'CTD_diseases_pathways',\n",
    "#     'CTD_pheno_term_ixns',\n",
    "#     'CTD_exposure_studies',\n",
    "#     'CTD_chemicals',\n",
    "#     'CTD_genes',\n",
    "    'CTD_chem_gene_ixns',\n",
    "    'CTD_chemicals_diseases',\n",
    "    'CTD_diseases'\n",
    "]\n",
    "\n",
    "for res in resources:\n",
    "    download_resource(res)\n",
    "\n",
    "\n",
    "def get_df(resource):\n",
    "    line_number = 27\n",
    "    the_file = 'unzipped_data/{resource}.csv'.format(resource=resource)\n",
    "    with open(the_file, 'r') as reader:\n",
    "        for i, row in enumerate(reader):\n",
    "            if i == line_number:\n",
    "                header = row.replace('# ', '').split(',')\n",
    "\n",
    "    # print(header)\n",
    "    df = pd.read_csv(the_file, skiprows=29, names=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de59c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseClassifier:\n",
    "    def __init__(self, input_df, parent_disease, gene_count, show_plots, use_class_weights, oversample):\n",
    "        self.input_df = input_df\n",
    "        self.parent_disease = parent_disease\n",
    "        self.target_diseases = self.get_diseases()\n",
    "        self.gene_count = gene_count\n",
    "        self.show_plots = show_plots\n",
    "        self.stop_early = True\n",
    "        self.use_class_weights = use_class_weights\n",
    "        self.oversample = oversample\n",
    "        self.top_n_genes = self.get_genes()\n",
    "    \n",
    "    def get_diseases(self):\n",
    "        \n",
    "        disease_df = get_df('CTD_diseases')\n",
    "        disease_df['ParentIDs'].str.split('|').explode()\n",
    "\n",
    "        hierarchy_df = disease_df\\\n",
    "            .assign(ParentIDs=disease_df['ParentIDs'].str.split('|')).explode('ParentIDs')\n",
    "\n",
    "        # top_of_tree = 'MESH:D010300' # parkinsons disease\n",
    "        # top_of_tree = 'MESH:D020734' # Parkinsonian Disorders\n",
    "        # top_of_tree = 'MESH:D019636' # neurodegenerative diseases\n",
    "        # top_of_tree = 'MESH:D009422' # nervous system diseases\n",
    "        top_of_tree = self.parent_disease\n",
    "        level_one = hierarchy_df.loc[hierarchy_df['ParentIDs'] == top_of_tree]\n",
    "        level_two = hierarchy_df.loc[hierarchy_df['ParentIDs'].isin(level_one['DiseaseID'])]\n",
    "        level_three = hierarchy_df.loc[hierarchy_df['ParentIDs'].isin(level_two['DiseaseID'])]\n",
    "\n",
    "        # to do, do this recursively..\n",
    "        all_diseases = list(level_one['DiseaseID'].unique()) \\\n",
    "                     + list(level_two['DiseaseID'].unique()) \\\n",
    "                     + list(level_three['DiseaseID'].unique()) \\\n",
    "                     + [top_of_tree]\n",
    "\n",
    "        return all_diseases\n",
    "    \n",
    "    def get_genes(self):\n",
    "        gene_df = pd.DataFrame(self.input_df.groupby(['InferenceGeneSymbol']).size()).reset_index()\n",
    "        gene_df.columns = ['InferenceGeneSymbol','cnt']\n",
    "        top_n_genes_df = gene_df.sort_values('cnt', ascending=False)[:self.gene_count]\n",
    "        top_n_genes = top_n_genes_df['InferenceGeneSymbol'].unique()\n",
    "\n",
    "        return top_n_genes\n",
    "    \n",
    "    def prep_training_data(self):\n",
    "        \n",
    "        gene_df = self.input_df.loc[self.input_df['DirectEvidence'].isnull()][['ChemicalName', 'DiseaseName', 'InferenceGeneSymbol', 'InferenceScore', 'DiseaseID']]\n",
    "\n",
    "        gene_df = gene_df.loc[gene_df['InferenceGeneSymbol'].isin(self.top_n_genes)]\n",
    "\n",
    "        evidence_df = self.input_df.loc[self.input_df['DirectEvidence'].notnull()][['ChemicalName', 'DiseaseName', 'DirectEvidence', 'DiseaseID']]\n",
    "        merged_df = gene_df.merge(evidence_df, on=['ChemicalName', 'DiseaseName', 'DiseaseID'])\n",
    "\n",
    "        dummy_df = pd.get_dummies(merged_df, prefix='', prefix_sep='',columns=['InferenceGeneSymbol'])\n",
    "        gb_df = dummy_df.groupby(['DiseaseName', 'ChemicalName', 'DiseaseID']).agg({np.max}).reset_index()\n",
    "\n",
    "        gb_df.columns = gb_df.columns.droplevel(1)\n",
    "\n",
    "        gb_df['label'] = np.where(gb_df['DirectEvidence'] == 'marker/mechanism',\n",
    "                                                   gb_df['InferenceScore'] * -1,\n",
    "                                                   gb_df['InferenceScore'])\n",
    "        \n",
    "        return gb_df\n",
    "    \n",
    "    def plot_results(self, history, predicted_values, y_test, accuracy):\n",
    "\n",
    "        auc_score = roc_auc_score(y_test, predicted_values) \n",
    "\n",
    "        if self.show_plots:\n",
    "            # plot accuracy\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "            axes[0][0].plot(history.history['accuracy'],label='accuracy')\n",
    "            axes[0][0].plot(history.history['val_accuracy'],label='val_accuracy')\n",
    "            axes[0][0].text(2, history.history['accuracy'][0] + .005, 'accuracy: {:.4f}'.format(accuracy))\n",
    "\n",
    "            axes[0][0].legend()\n",
    "\n",
    "            # plot loss\n",
    "            axes[0][1].plot(history.history['loss'],label='loss')\n",
    "            axes[0][1].plot(history.history['val_loss'],label='val_loss')\n",
    "            axes[0][1].legend()\n",
    "            fig.tight_layout()\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve (y_test , predicted_values)\n",
    "\n",
    "            # plot_roc_curve\n",
    "            axes[1][0].plot(fpr,tpr)\n",
    "            axes[1][0].text(0.7, 0.9, 'auc: {:.4f}'.format(auc_score))\n",
    "            axes[1][0].axis([-.05,1.1,0,1.05]) \n",
    "\n",
    "            # plot confusion matrix\n",
    "            cm = confusion_matrix(y_test, np.where(predicted_values > 0.5, 1, 0))\n",
    "\n",
    "            labels = [\"Non Target\", \"Target\"]\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "            disp.plot(cmap=plt.cm.Blues, ax=axes[1][1]) # xticks_rotation=45\n",
    "\n",
    "        return auc_score\n",
    "    \n",
    "    def get_class_weights(self, labels):\n",
    "        \"\"\"\n",
    "        To Do - make this dynamic to deal with N classes\n",
    "        \"\"\"\n",
    "        neg, pos = np.bincount(labels)\n",
    "        total = neg + pos\n",
    "#         print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "#             total, pos, 100 * pos / total))\n",
    "\n",
    "        # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "        # The sum of the weights of all examples stays the same.\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "        # print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "        # print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "        \n",
    "        return class_weight\n",
    "\n",
    "\n",
    "    def train_model(self, train_df):\n",
    "        \n",
    "        gene_columns = train_df.columns.intersection(self.top_n_genes)\n",
    "        shuffled_df = train_df.sample(frac=1)\n",
    "        features, labels = shuffled_df[gene_columns], shuffled_df['binary_label']\n",
    "        input_shape = features.shape[1]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=0, train_size=TRAIN_SIZE)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(60, input_dim=input_shape, activation='relu'))\n",
    "        model.add(Dense(6, input_dim=input_shape, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "\n",
    "        callbacks = []\n",
    "        if self.stop_early:\n",
    "            callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2))\n",
    "\n",
    "        model_fit_kw = {\n",
    "            'x': X_train,\n",
    "            'y': y_train,\n",
    "            'epochs':25,\n",
    "            'validation_split':0.2,\n",
    "            'callbacks':callbacks,\n",
    "            'verbose':VERBOSE\n",
    "        }\n",
    "        if self.use_class_weights:\n",
    "            model_fit_kw['class_weight'] = self.get_class_weights(labels)\n",
    "        \n",
    "        ## fit the model\n",
    "        history = model.fit(**model_fit_kw)\n",
    "        \n",
    "        ## make predictions on the test set\n",
    "        predicted_values = model.predict(X_test)\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "\n",
    "        auc = self.plot_results(history, predicted_values, y_test, accuracy)\n",
    "\n",
    "        model_metrics = m.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "        model_keys = ['loss'] + [m.name for m in the_metrics]\n",
    "        metrics_info = dict(zip(model_keys, model_metrics))\n",
    "        \n",
    "        return {\n",
    "            'history':history, \n",
    "            'model': model, \n",
    "            'auc': auc, \n",
    "            'metrics_info': metrics_info\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "    def main(self):\n",
    "        train_df = self.prep_training_data()\n",
    "        target_diseases = self.get_diseases()\n",
    "        train_df['binary_label'] = np.where(train_df['DiseaseID'].isin(target_diseases),1, 0)\n",
    "        \n",
    "        history, model, auc, model_metrics =  self.train_model(train_df)\n",
    "        # print(x)\n",
    "        \n",
    "\n",
    "        \n",
    "input_df = get_df('CTD_chemicals_diseases')\n",
    "        \n",
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D019636', # neurodegenerative diseases\n",
    "    'gene_count': 1000,\n",
    "    'show_plots': True,\n",
    "    'use_class_weights': True,\n",
    "    'oversample': False\n",
    "}\n",
    "dc = DiseaseClassifier(**kw)\n",
    "dc.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
