{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bd19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, metrics\n",
    "from keras.layers import Input, Dense, BatchNormalization, LSTM, Embedding, Bidirectional, Normalization, Conv1D, Dropout, MaxPool2D,MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5082900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 10:12:20.804655: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "VERBOSE=False\n",
    "EPOCHS=25\n",
    "TRAIN_SIZE=.75\n",
    "\n",
    "METRICS = [\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'), \n",
    "      metrics.BinaryAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc'),\n",
    "      metrics.AUC(name='prc', curve='PR')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1014f5d",
   "metadata": {},
   "source": [
    "## get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a274f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: CTD_chem_gene_ixns\n",
      "data already exists\n",
      "downloading: CTD_chemicals_diseases\n",
      "data already exists\n",
      "downloading: CTD_diseases\n",
      "data already exists\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def download_resource(resource):\n",
    "    url_dl_pattern = 'http://ctdbase.org/reports/{resource}.csv.gz'\n",
    "    url = url_dl_pattern.format(resource=resource)\n",
    "    \n",
    "    print('downloading: {0}'.format(resource))\n",
    "    local_filename = 'zipped_data/' + url.split('/')[-1]\n",
    "    unzipped_filename = 'unzipped_data/' + url.split('/')[-1].replace('.gz', '')\n",
    "    \n",
    "    if os.path.isfile(unzipped_filename):\n",
    "        print('data already exists')\n",
    "        return \n",
    "\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "\n",
    "    with gzip.open(local_filename, 'rb') as f_in:\n",
    "        with open(unzipped_filename, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "    return local_filename\n",
    "\n",
    "\n",
    "resources = [\n",
    "#     'CTD_chem_gene_ixn_types',\n",
    "#     'CTD_chem_pathways_enriched',\n",
    "#     'CTD_genes_diseases',\n",
    "#     'CTD_genes_pathways',\n",
    "#     'CTD_diseases_pathways',\n",
    "#     'CTD_pheno_term_ixns',\n",
    "#     'CTD_exposure_studies',\n",
    "#     'CTD_chemicals',\n",
    "#     'CTD_genes',\n",
    "    'CTD_chem_gene_ixns',\n",
    "    'CTD_chemicals_diseases',\n",
    "    'CTD_diseases'\n",
    "]\n",
    "\n",
    "for res in resources:\n",
    "    download_resource(res)\n",
    "\n",
    "\n",
    "def get_df(resource):\n",
    "    line_number = 27 ## all the files have the same header \n",
    "    the_file = 'unzipped_data/{resource}.csv'.format(resource=resource)\n",
    "    with open(the_file, 'r') as reader:\n",
    "        for i, row in enumerate(reader):\n",
    "            if i == line_number:\n",
    "                header = row.replace('# ', '').split(',')\n",
    "\n",
    "    df = pd.read_csv(the_file, skiprows=29, names=header)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43dcc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseClassifier:\n",
    "    def __init__(self, input_df, parent_disease, gene_count, show_plots, use_class_weights, oversample, model_type, classification='binary'):\n",
    "        self.input_df = input_df\n",
    "        self.parent_disease = parent_disease\n",
    "        self.target_diseases = self.get_diseases()\n",
    "        self.gene_count = gene_count\n",
    "        self.show_plots = show_plots\n",
    "        self.stop_early = True\n",
    "        self.use_class_weights = use_class_weights\n",
    "        self.oversample = oversample\n",
    "        self.model_type = model_type\n",
    "        self.classification = classification\n",
    "        self.top_n_genes = self.get_genes()\n",
    "\n",
    "        if self.use_class_weights and self.oversample:\n",
    "            raise Exception('Need to either use classweights OR oversample')\n",
    "    \n",
    "    def get_diseases(self):\n",
    "        \n",
    "        disease_df = get_df('CTD_diseases')\n",
    "        disease_df['ParentIDs'].str.split('|').explode()\n",
    "\n",
    "        hierarchy_df = disease_df\\\n",
    "            .assign(ParentIDs=disease_df['ParentIDs'].str.split('|')).explode('ParentIDs')\n",
    "        \n",
    "        levels = 3\n",
    "        \n",
    "        all_diseases = [self.parent_disease]\n",
    "        current_level = hierarchy_df.loc[hierarchy_df['ParentIDs'] == self.parent_disease]\n",
    "        for level in range(levels):\n",
    "            children = list(current_level['DiseaseID'].unique())\n",
    "            all_diseases.extend(children)\n",
    "            next_level = hierarchy_df.loc[hierarchy_df['ParentIDs'].isin(children)]\n",
    "            current_level = next_level\n",
    "        \n",
    "        return all_diseases\n",
    "    \n",
    "    def get_genes(self):\n",
    "        gene_df = pd.DataFrame(self.input_df.groupby(['InferenceGeneSymbol']).size()).reset_index()\n",
    "        gene_df.columns = ['InferenceGeneSymbol','cnt']\n",
    "        top_n_genes_df = gene_df.sort_values('cnt', ascending=False)[:self.gene_count]\n",
    "        top_n_genes = top_n_genes_df['InferenceGeneSymbol'].unique()\n",
    "\n",
    "        return top_n_genes\n",
    "    \n",
    "    def prep_training_data(self):\n",
    "        \n",
    "        gene_df = self.input_df.loc[self.input_df['DirectEvidence'].isnull()][['ChemicalName', 'DiseaseName', 'InferenceGeneSymbol', 'InferenceScore', 'DiseaseID']]\n",
    "\n",
    "        gene_df = gene_df.loc[gene_df['InferenceGeneSymbol'].isin(self.top_n_genes)]\n",
    "\n",
    "        evidence_df = self.input_df.loc[self.input_df['DirectEvidence'].notnull()][['ChemicalName', 'DiseaseName', 'DirectEvidence', 'DiseaseID']]\n",
    "        merged_df = gene_df.merge(evidence_df, on=['ChemicalName', 'DiseaseName', 'DiseaseID'])\n",
    "\n",
    "        dummy_df = pd.get_dummies(merged_df, prefix='', prefix_sep='',columns=['InferenceGeneSymbol'])\n",
    "        gb_df = dummy_df.groupby(['DiseaseName', 'ChemicalName', 'DiseaseID']).agg({np.max}).reset_index()\n",
    "\n",
    "        gb_df.columns = gb_df.columns.droplevel(1)\n",
    "\n",
    "        gb_df['label'] = np.where(gb_df['DirectEvidence'] == 'marker/mechanism',\n",
    "                                                   gb_df['InferenceScore'] * -1,\n",
    "                                                   gb_df['InferenceScore'])\n",
    "        \n",
    "        return gb_df\n",
    "    \n",
    "    def plot_results(self, history, predicted_values, y_test, accuracy):\n",
    "\n",
    "        ## to do, subclass categorical classifications.. override this method\n",
    "        if self.classification == 'categorical':\n",
    "\n",
    "            cm = confusion_matrix(y_test.argmax(axis=1), predicted_values.argmax(axis=1))\n",
    "\n",
    "            labels = ['Not Relevant', 'Therapeutic', 'Negative']\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "            disp.plot(cmap=plt.cm.Blues) # xticks_rotation=45\n",
    "            return 0\n",
    "\n",
    "    \n",
    "        auc_score = roc_auc_score(y_test, predicted_values) \n",
    "        \n",
    "        if not self.show_plots:\n",
    "            return auc_score\n",
    "        \n",
    "        # plot accuracy\n",
    "        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "        axes[0][0].plot(history.history['accuracy'],label='accuracy')\n",
    "        axes[0][0].plot(history.history['val_accuracy'],label='val_accuracy')\n",
    "        axes[0][0].text(2, history.history['accuracy'][0] + .005, 'accuracy: {:.4f}'.format(accuracy))\n",
    "\n",
    "        axes[0][0].legend()\n",
    "\n",
    "        # plot loss\n",
    "        axes[0][1].plot(history.history['loss'],label='loss')\n",
    "        axes[0][1].plot(history.history['val_loss'],label='val_loss')\n",
    "        axes[0][1].legend()\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve (y_test , predicted_values)\n",
    "\n",
    "        # plot_roc_curve\n",
    "        axes[1][0].plot(fpr,tpr)\n",
    "        axes[1][0].text(0.7, 0.9, 'auc: {:.4f}'.format(auc_score))\n",
    "        axes[1][0].axis([-.05,1.1,0,1.05]) \n",
    "\n",
    "        # plot confusion matrix\n",
    "        cm = confusion_matrix(y_test, np.where(predicted_values > 0.5, 1, 0))\n",
    "\n",
    "        labels = [\"Non Target\", \"Target\"]\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "        disp.plot(cmap=plt.cm.Blues, ax=axes[1][1]) # xticks_rotation=45\n",
    "\n",
    "        return auc_score\n",
    "    \n",
    "    def get_class_weights(self, labels):\n",
    "        \"\"\"\n",
    "        Determine the weights to assign to each class based on the distribution of classes \n",
    "        \"\"\"\n",
    "\n",
    "        classes = labels.unique()\n",
    "        total_classes = len(classes)\n",
    "\n",
    "        total = len(labels)\n",
    "\n",
    "        cl_weight = {}\n",
    "        for cl in classes:\n",
    "            count_of_this_class = len([x for x in labels if x == cl]) # optimize this.. \n",
    "            cl_weight[cl] = (1 / count_of_this_class) * (total / total_classes)\n",
    "\n",
    "        return cl_weight\n",
    "    \n",
    "    def get_model(self, input_shape, output_shape):\n",
    "        model = Sequential()\n",
    "        \n",
    "        \n",
    "        if self.model_type == 'CNN':\n",
    "            model.add(Conv1D(64, 2, activation=\"relu\", input_shape=(input_shape,1)))\n",
    "            model.add(Dense(16, activation=\"relu\"))\n",
    "            model.add(MaxPooling1D())\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(output_shape, activation = 'sigmoid'))\n",
    "        else:\n",
    "            model.add(Dense(60, input_dim=input_shape, activation='relu'))\n",
    "            model.add(Dense(6, input_dim=input_shape, activation='relu'))\n",
    "            model.add(Dense(output_shape, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss=self.classification + '_crossentropy', optimizer='adam', metrics=METRICS)\n",
    "        return model\n",
    "    \n",
    "    def over_sample(self, X_train, y_train):\n",
    "        if self.classification == 'categorical':\n",
    "            raise Exception('over sampling not supported with categorical classifications')\n",
    "        bool_train_labels = y_train != 0\n",
    "\n",
    "        pos_features = X_train[bool_train_labels]\n",
    "        neg_features = X_train[~bool_train_labels]\n",
    "\n",
    "        pos_labels = y_train[bool_train_labels]\n",
    "        neg_labels = y_train[~bool_train_labels]\n",
    "\n",
    "        ids = np.arange(len(pos_features))\n",
    "        choices = np.random.choice(ids, len(neg_features))\n",
    "\n",
    "        res_pos_features = pos_features.iloc[choices, :]\n",
    "        res_pos_labels = pos_labels.values[choices] # pos_labels.array(choices)\n",
    "\n",
    "        res_pos_features.shape\n",
    "\n",
    "        resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
    "        resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
    "\n",
    "        order = np.arange(len(resampled_labels))\n",
    "        np.random.shuffle(order)\n",
    "        resampled_features = resampled_features[order]\n",
    "        resampled_labels = resampled_labels[order]\n",
    "\n",
    "        return resampled_features, resampled_labels\n",
    "        \n",
    "    def train_model(self, train_df):\n",
    "\n",
    "        gene_columns = train_df.columns.intersection(self.top_n_genes)\n",
    "        shuffled_df = train_df.sample(frac=1)\n",
    "        features, labels = shuffled_df[gene_columns], shuffled_df['binary_label']\n",
    "        \n",
    "        if self.classification == 'categorical':\n",
    "            enc = OneHotEncoder()\n",
    "            labels = enc.fit_transform(shuffled_df['categorical_label'][:, np.newaxis]).toarray()\n",
    "        \n",
    "        output_layer_num = labels.shape[1] if self.classification == 'categorical' else 1\n",
    "        model = self.get_model(features.shape[1], output_layer_num)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=0, train_size=TRAIN_SIZE)\n",
    "        \n",
    "        if self.oversample:\n",
    "            X_train, y_train = self.over_sample(X_train, y_train)\n",
    "        \n",
    "        callbacks = []\n",
    "        if self.stop_early:\n",
    "            callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2))\n",
    "\n",
    "        \n",
    "        model_fit_kw = {\n",
    "            'x': X_train,\n",
    "            'y': y_train,\n",
    "            'epochs':25,\n",
    "            'validation_split':0.2,\n",
    "            'callbacks':callbacks,\n",
    "            'verbose':VERBOSE\n",
    "        }\n",
    "        if self.use_class_weights:\n",
    "            label_column = self.classification + '_label'\n",
    "            model_fit_kw['class_weight'] = self.get_class_weights(train_df[label_column])\n",
    "        \n",
    "        ## fit the model\n",
    "        history = model.fit(**model_fit_kw)\n",
    "        \n",
    "        ## make predictions on the test set\n",
    "        predicted_values = model.predict(X_test)\n",
    "\n",
    "        model_metrics = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "        model_keys = ['loss'] + [m.name for m in METRICS]\n",
    "        metrics_info = dict(zip(model_keys, model_metrics))\n",
    "\n",
    "        auc = self.plot_results(history, predicted_values, y_test, metrics_info.get('accuracy'))\n",
    "\n",
    "        \n",
    "        return history,model, auc, metrics_info\n",
    "\n",
    "    def apply_category(self, row):\n",
    "        if row.binary_label == 0:\n",
    "            return 0 # 'Not Releveant'\n",
    "        if row.DirectEvidence == 'marker/mechanism':\n",
    "            return 1 # 'Negative'\n",
    "        else:\n",
    "            return 2 # 'Therapeutic'\n",
    "    \n",
    "    def set_label(self, train_df):\n",
    "\n",
    "        target_diseases = self.get_diseases()\n",
    "        train_df['binary_label'] = np.where(train_df['DiseaseID'].isin(target_diseases),1, 0)\n",
    "\n",
    "        if self.classification == 'categorical':\n",
    "            train_df['categorical_label'] = train_df.apply(lambda row: self.apply_category(row), axis=1)\n",
    "\n",
    "        return train_df\n",
    "        \n",
    "   \n",
    "    def main(self):\n",
    "        train_df = self.prep_training_data()\n",
    "        train_df = self.set_label(train_df)\n",
    "        history, model, auc, model_metrics =  self.train_model(train_df)\n",
    "\n",
    "        model_metrics['parent_disease'] = self.parent_disease\n",
    "        model_metrics['gene_count'] = self.gene_count\n",
    "        model_metrics['show_plots'] = self.show_plots\n",
    "        model_metrics['use_class_weights'] = self.use_class_weights\n",
    "        model_metrics['oversample'] = self.oversample\n",
    "        model_metrics['model_type'] = self.model_type\n",
    "               \n",
    "        return model_metrics, model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8059677",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = get_df('CTD_chemicals_diseases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603200de",
   "metadata": {},
   "source": [
    "## DNN with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08218af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D019636', # neurodegenerative diseases\n",
    "    'gene_count': 1000,\n",
    "    'model_type':'DNN',\n",
    "    'show_plots': True,\n",
    "    'use_class_weights': True,\n",
    "    'oversample': False\n",
    "}\n",
    "dc = DiseaseClassifier(**kw)\n",
    "dc_mm, _ = dc.main()\n",
    "display(pd.DataFrame([mm]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59939cc",
   "metadata": {},
   "source": [
    "## CNN with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D019636', # neurodegenerative diseases\n",
    "    'gene_count': 1000,\n",
    "    'model_type':'CNN',\n",
    "    'show_plots': True,\n",
    "    'use_class_weights': True,\n",
    "    'oversample': False\n",
    "}\n",
    "cnn_dc = DiseaseClassifier(**kw)\n",
    "cnn_dc_mm, _ = cnn_dc.main()\n",
    "display(pd.DataFrame([mm]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797a79d",
   "metadata": {},
   "source": [
    "## DNN with Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29961d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D019636', # neurodegenerative diseases\n",
    "    'gene_count': 1000,\n",
    "    'model_type':'DNN',\n",
    "    'show_plots': True,\n",
    "    'use_class_weights': False,\n",
    "    'oversample': True\n",
    "}\n",
    "dnn_os, _ = DiseaseClassifier(**kw)\n",
    "mm = dnn_os.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50367807",
   "metadata": {},
   "source": [
    "## Iterate over a number of different permutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4da1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from itertools import product\n",
    "\n",
    "params = {\n",
    "    'gene_count': [20, 50, 100, 250, 500, 1000, 2000, 3000, 5000],\n",
    "    'parent_disease': ['MESH:D019636'],\n",
    "    'model_type': ['CNN', 'DNN'],\n",
    "    'use_class_weights': [True, False],\n",
    "    'oversample': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "permutations = [dict(zip(params, v)) for v in product(*params.values())]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, (p) in enumerate(permutations):\n",
    "    p['input_df'] = input_df\n",
    "    p['show_plots'] = False\n",
    "    try:\n",
    "        _m = DiseaseClassifier(**p)\n",
    "    except Exception:\n",
    "        continue\n",
    "    \n",
    "    model_results, _ = _m.main()\n",
    "    with open('out_stream.txt', 'a') as f:\n",
    "        f.write(json.dumps(model_results) + '\\n')\n",
    "    results.append(model_results)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "df.to_csv('final-output/{ts}.csv'.format(ts=now))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1d88e",
   "metadata": {},
   "source": [
    "## what are the best params to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9ecd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>loss</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>prc</th>\n",
       "      <th>parent_disease</th>\n",
       "      <th>gene_count</th>\n",
       "      <th>show_plots</th>\n",
       "      <th>use_class_weights</th>\n",
       "      <th>oversample</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.257295</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>10604.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.882930</td>\n",
       "      <td>0.074050</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>0.969943</td>\n",
       "      <td>0.407529</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.191398</td>\n",
       "      <td>104.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>11114.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.924205</td>\n",
       "      <td>0.102463</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.978981</td>\n",
       "      <td>0.502584</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.176474</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>11906.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.908761</td>\n",
       "      <td>0.088482</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.972901</td>\n",
       "      <td>0.662647</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.149193</td>\n",
       "      <td>123.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>11876.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.926707</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.904412</td>\n",
       "      <td>0.970390</td>\n",
       "      <td>0.654905</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.206814</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>9738.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.900165</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.967957</td>\n",
       "      <td>0.709861</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.377660</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>7509.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.766509</td>\n",
       "      <td>0.039183</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.939280</td>\n",
       "      <td>0.439189</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.284652</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>9420.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.871523</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.958483</td>\n",
       "      <td>0.490371</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.297765</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>8377.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.853312</td>\n",
       "      <td>0.056826</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.953417</td>\n",
       "      <td>0.352422</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>11886.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.914357</td>\n",
       "      <td>0.101297</td>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.965925</td>\n",
       "      <td>0.543524</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.181212</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>11695.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.912805</td>\n",
       "      <td>0.100243</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.972133</td>\n",
       "      <td>0.509848</td>\n",
       "      <td>MESH:D019636</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0      loss     tp      fp       tn    fn  accuracy  precision  \\\n",
       "18          18  0.257295  113.0  1413.0  10604.0   8.0  0.882930   0.074050   \n",
       "19          19  0.191398  104.0   911.0  11114.0   9.0  0.924205   0.102463   \n",
       "51          51  0.176474  116.0  1195.0  11906.0  12.0  0.908761   0.088482   \n",
       "33          33  0.149193  123.0   936.0  11876.0  13.0  0.926707   0.116147   \n",
       "15          15  0.206814   99.0  1080.0   9738.0  11.0  0.900165   0.083969   \n",
       "6            6  0.377660   94.0  2305.0   7509.0  11.0  0.766509   0.039183   \n",
       "13          13  0.284652  104.0  1391.0   9420.0  13.0  0.871523   0.069565   \n",
       "7            7  0.297765   87.0  1444.0   8377.0  11.0  0.853312   0.056826   \n",
       "36          36  0.207912  125.0  1109.0  11886.0  16.0  0.914357   0.101297   \n",
       "30          30  0.181212  124.0  1113.0  11695.0  16.0  0.912805   0.100243   \n",
       "\n",
       "      recall       auc       prc parent_disease  gene_count  show_plots  \\\n",
       "18  0.933884  0.969943  0.407529   MESH:D019636         250       False   \n",
       "19  0.920354  0.978981  0.502584   MESH:D019636         250       False   \n",
       "51  0.906250  0.972901  0.662647   MESH:D019636        5000       False   \n",
       "33  0.904412  0.970390  0.654905   MESH:D019636        1000       False   \n",
       "15  0.900000  0.967957  0.709861   MESH:D019636         100       False   \n",
       "6   0.895238  0.939280  0.439189   MESH:D019636          50       False   \n",
       "13  0.888889  0.958483  0.490371   MESH:D019636         100       False   \n",
       "7   0.887755  0.953417  0.352422   MESH:D019636          50       False   \n",
       "36  0.886525  0.965925  0.543524   MESH:D019636        2000       False   \n",
       "30  0.885714  0.972133  0.509848   MESH:D019636        1000       False   \n",
       "\n",
       "    use_class_weights  oversample model_type  \n",
       "18               True       False        CNN  \n",
       "19              False        True        CNN  \n",
       "51               True       False        DNN  \n",
       "33               True       False        DNN  \n",
       "15               True       False        DNN  \n",
       "6                True       False        CNN  \n",
       "13              False        True        CNN  \n",
       "7               False        True        CNN  \n",
       "36               True       False        CNN  \n",
       "30               True       False        CNN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## what are the best params to use?\n",
    "\n",
    "results_df = pd.read_csv('final-output/2022-02-28 17:06:09.csv')\n",
    "display(results_df.sort_values('recall', ascending=False)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad22bb7",
   "metadata": {},
   "source": [
    "## DNN with Multi Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a87dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this\n",
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D019636', # neurodegenerative diseases\n",
    "    'gene_count': 1000,\n",
    "    'model_type':'DNN',\n",
    "    'show_plots': True,\n",
    "    'use_class_weights': True,\n",
    "    'oversample': False,\n",
    "    'classification': 'categorical'\n",
    "}\n",
    "cat = DiseaseClassifier(**kw)\n",
    "mm, _ = cat.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce70d5",
   "metadata": {},
   "source": [
    "### Here we evaluate the chemicals that have posibile therapeutic and harmful effects as it relates to.  We take the chemical to gene network.  I want to see chemicals *not* in the dataset that we can research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the model to get the relevant genes that we need to process.. dont need to fit the model yet\n",
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D019636', # neurodegenerative diseases\n",
    "    'gene_count': 1000,\n",
    "    'show_plots': False,\n",
    "    'oversample': False,\n",
    "    'use_class_weights': True,\n",
    "    'classification': 'categorical'\n",
    "}\n",
    "chem_cl = DiseaseClassifier(**kw)\n",
    "\n",
    "inp_df = get_df('CTD_chem_gene_ixns')\n",
    "inp_df = inp_df[inp_df['GeneSymbol'].isin(chem_cl.top_n_genes)]\n",
    "\n",
    "## process the chemical -> dataset ( without disease ) in the same way we do our input data\n",
    "gb_df = inp_df.groupby(['ChemicalName', 'GeneSymbol']).size().reset_index()\n",
    "gb_df.columns = ['ChemicalName','GeneSymbol', 'InteractionCount']\n",
    "dummy_df = pd.get_dummies(gb_df, prefix='', prefix_sep='',columns=['GeneSymbol'])\n",
    "\n",
    "chem_df = dummy_df.groupby(['ChemicalName']).agg({np.max}).reset_index()\n",
    "chem_df.columns = chem_df.columns.droplevel(1)\n",
    "\n",
    "# results, chem_cl_model = chem_cl.main()\n",
    "\n",
    "predicted_values = chem_cl_model.predict(chem_df[chem_cl.top_n_genes])\n",
    "\n",
    "predicted_value_df = pd.DataFrame(predicted_values, columns=['Ther', 'Not Relevant', 'Marker'])\n",
    "\n",
    "final = chem_df.merge(predicted_value_df, left_index=True, right_index=True)\n",
    "final = final[['ChemicalName', 'Ther', 'Not Relevant', 'Marker']]\n",
    "\n",
    "print('--- THER ---')\n",
    "display(final.nlargest(5, 'Ther'))\n",
    "\n",
    "print('--- MARKER ---')\n",
    "display(final.nlargest(5, 'Marker'))\n",
    "\n",
    "# chem_df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b426b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ctd says (+)-JQ1 compound\t is associated with the reduction of inflamation\n",
    "## pub chem says trimethyllead is acutely toxic - https://pubchem.ncbi.nlm.nih.gov/compound/Trimethyllead-acetate is \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205068c1",
   "metadata": {},
   "source": [
    "## Understanding feature importance -- what genes are coorelated with Parkinsons / Neurodegenerative diseass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def feature_importance(features, labels, stop_early=True, show_plots=True):\n",
    "    input_shape = features.shape[1]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=0, train_size=TRAIN_SIZE)\n",
    "\n",
    "    rand_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rand_forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "    optimal_node_count = 128\n",
    "    feature_count = 70\n",
    "    output_label_len = 10\n",
    "    imp_arr = rand_forest_classifier.feature_importances_\n",
    "    \n",
    "    gene_importance = dict(zip(features.columns, imp_arr))\n",
    "    gene_importance_df = pd.DataFrame({'gene': features.columns, 'score': imp_arr})\n",
    "\n",
    "    return gene_importance_df.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdd4b4e",
   "metadata": {},
   "source": [
    "## Gene Importance for Neurodegenrative Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979145ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## do this\n",
    "\n",
    "train_df = chem_cl.prep_training_data()\n",
    "train_df = chem_cl.set_label(train_df)\n",
    "\n",
    "gene_columns = train_df.columns.intersection(chem_cl.top_n_genes)\n",
    "\n",
    "print(len(gene_columns))\n",
    "shuffled_df = train_df.sample(frac=1)\n",
    "\n",
    "gene_importance_df = feature_importance(shuffled_df[gene_columns], shuffled_df['binary_label'])\n",
    "\n",
    "\n",
    "## https://www.nature.com/articles/ng0892-345 # APP shows up... has strong inference to alzheimers\n",
    "gene_importance_df.hist()\n",
    "\n",
    "ax = gene_importance_df[:20].plot.bar(y='score', x='gene', rot=0, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e4d2c",
   "metadata": {},
   "source": [
    "## Gene Importance for Parkinsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52de097",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = {\n",
    "    'input_df': input_df,\n",
    "    'parent_disease': 'MESH:D010300', # parkinsons diseases\n",
    "    'gene_count': 1000,\n",
    "    'model_type':'DNN',\n",
    "    'show_plots': False,\n",
    "    'oversample': True,\n",
    "    'use_class_weights': False,\n",
    "    'classification': 'binary'\n",
    "}\n",
    "park_cl = DiseaseClassifier(**kw)\n",
    "results, park_model = park_cl.main()\n",
    "\n",
    "\n",
    "train_df = park_cl.prep_training_data()\n",
    "train_df = park_cl.set_label(train_df)\n",
    "\n",
    "gene_columns = train_df.columns.intersection(park_cl.top_n_genes)\n",
    "\n",
    "print(len(gene_columns))\n",
    "shuffled_df = train_df.sample(frac=1)\n",
    "\n",
    "park_gene_importance_df = feature_importance(shuffled_df[gene_columns], shuffled_df['binary_label'])\n",
    "\n",
    "\n",
    "## https://www.nature.com/articles/ng0892-345 # APP shows up... has strong inference to alzheimers\n",
    "\n",
    "ax = park_gene_importance_df[:20].plot.bar(y='score', x='gene', rot=0, figsize=(20,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbee0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Future Work \n",
    "# - use the random forest gene importance to better select the features\n",
    "# - PCA\n",
    "# - regression model for predicting inference score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
